{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Supriyagattu/NLP/blob/main/2403A52230_B09_NLP_Lab_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Gensim"
      ],
      "metadata": {
        "id": "9TzZGKkcUGlG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9tm9iyyEkcm",
        "outputId": "12b62db6-0e6a-4537-9e41-f714e9eb7b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ],
      "metadata": {
        "id": "wAuPBzvPNJhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gensim is used to load and work with pre-trained word embedding models\n",
        "# It provides Word2Vec, GloVe, FastText implementations\n",
        "import gensim\n",
        "\n",
        "# KeyedVectors is specifically used to load pre-trained word embeddings\n",
        "# without loading the full training model\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# numpy is used for numerical operations on vectors\n",
        "# Word embeddings are stored as numerical arrays\n",
        "import numpy as np\n",
        "\n",
        "# sklearn.metrics.pairwise is used to calculate similarity between vectors\n",
        "# cosine_similarity helps measure semantic similarity between words\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# matplotlib is used to visualize word embeddings in 2D space\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "Gcu0RWz_NKLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Word2Vec and find numerical vector representation of words"
      ],
      "metadata": {
        "id": "1YyKMl6VNSlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load pre-trained Word2Vec model (may take time on first download)\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Print vocabulary size\n",
        "print(\"Vocabulary Size:\", len(model.key_to_index))\n",
        "\n",
        "# Display vector for a sample word\n",
        "word = \"king\"\n",
        "vector = model[word]\n",
        "\n",
        "print(\"\\nWord:\", word)\n",
        "print(\"Vector length:\", len(vector))\n",
        "print(\"First 10 values of the vector:\\n\", vector[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUgl6oZmNfHq",
        "outputId": "f40493bc-dba6-4083-adb9-455dfe337995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Vocabulary Size: 3000000\n",
            "\n",
            "Word: king\n",
            "Vector length: 300\n",
            "First 10 values of the vector:\n",
            " [ 0.12597656  0.02978516  0.00860596  0.13964844 -0.02563477 -0.03613281\n",
            "  0.11181641 -0.19824219  0.05126953  0.36328125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Glove and find numerical vector representation of words"
      ],
      "metadata": {
        "id": "7wcbUbx3OmK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load GloVe embeddings (100-dimensional)\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Print vocabulary size\n",
        "print(\"Vocabulary Size:\", len(model.key_to_index))\n",
        "\n",
        "# Display vector for a sample word\n",
        "word = \"king\"\n",
        "vector = model[word]\n",
        "\n",
        "print(\"\\nWord:\", word)\n",
        "print(\"Vector length:\", len(vector))\n",
        "print(\"First 10 values of the vector:\\n\", vector[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5ULmNFuOm5c",
        "outputId": "809b6539-5dd3-4b4d-b6e3-9019f5901df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "Vocabulary Size: 400000\n",
            "\n",
            "Word: king\n",
            "Vector length: 100\n",
            "First 10 values of the vector:\n",
            " [-0.32307 -0.87616  0.21977  0.25268  0.22976  0.7388  -0.37954 -0.35307\n",
            " -0.84369 -1.1113 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec – Word Similarity"
      ],
      "metadata": {
        "id": "f5Dz16pRTLBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Word2Vec Similarity Scores:\\n\")\n",
        "\n",
        "word_pairs = [\n",
        "    (\"doctor\", \"nurse\"),\n",
        "    (\"cat\", \"dog\"),\n",
        "    (\"king\", \"queen\"),\n",
        "    (\"car\", \"bus\"),\n",
        "    (\"man\", \"woman\")\n",
        "]\n",
        "\n",
        "for w1, w2 in word_pairs:\n",
        "    similarity = model.similarity(w1, w2)\n",
        "    print(f\"{w1} - {w2} : {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcD9VKzVTLlR",
        "outputId": "d02b8bc3-b572-40f4-d06f-c77b092848dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec Similarity Scores:\n",
            "\n",
            "doctor - nurse : 0.6320\n",
            "cat - dog : 0.7609\n",
            "king - queen : 0.6511\n",
            "car - bus : 0.4693\n",
            "man - woman : 0.7664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Glove and complete word similarity"
      ],
      "metadata": {
        "id": "idv0u1kjRNoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained GloVe model (100D)\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Define word pairs\n",
        "word_pairs = [\n",
        "    (\"doctor\", \"nurse\"),\n",
        "    (\"cat\", \"dog\"),\n",
        "    (\"car\", \"bus\"),\n",
        "    (\"king\", \"queen\"),\n",
        "    (\"man\", \"woman\"),\n",
        "    (\"teacher\", \"student\"),\n",
        "    (\"apple\", \"banana\"),\n",
        "    (\"computer\", \"keyboard\"),\n",
        "    (\"sun\", \"moon\"),\n",
        "    (\"river\", \"water\")\n",
        "]\n",
        "\n",
        "print(\"Word Similarity Scores:\\n\")\n",
        "\n",
        "for w1, w2 in word_pairs:\n",
        "    similarity = model.similarity(w1, w2)\n",
        "    print(f\"{w1} - {w2} : {similarity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GATl3VArRONp",
        "outputId": "2b4caed1-1608-4920-c682-5e9387779774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Similarity Scores:\n",
            "\n",
            "doctor - nurse : 0.7522\n",
            "cat - dog : 0.8798\n",
            "car - bus : 0.7373\n",
            "king - queen : 0.7508\n",
            "man - woman : 0.8323\n",
            "teacher - student : 0.8083\n",
            "apple - banana : 0.5054\n",
            "computer - keyboard : 0.5418\n",
            "sun - moon : 0.6138\n",
            "river - water : 0.6306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec – Nearest Neighbor Words"
      ],
      "metadata": {
        "id": "08w6ap2BTeAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_words = [\"king\", \"university\", \"doctor\", \"car\", \"music\"]\n",
        "\n",
        "for word in chosen_words:\n",
        "    print(f\"\\nTop similar words for '{word}' (Word2Vec):\\n\")\n",
        "    similar_words = model.most_similar(word, topn=5)\n",
        "    for similar_word, score in similar_words:\n",
        "        print(f\"{similar_word} : {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoWAkjxuTexf",
        "outputId": "62f48ad9-a170-4f53-a41a-ea430d080e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top similar words for 'king' (Word2Vec):\n",
            "\n",
            "kings : 0.7138\n",
            "queen : 0.6511\n",
            "monarch : 0.6413\n",
            "crown_prince : 0.6204\n",
            "prince : 0.6160\n",
            "\n",
            "Top similar words for 'university' (Word2Vec):\n",
            "\n",
            "universities : 0.7004\n",
            "faculty : 0.6781\n",
            "unversity : 0.6758\n",
            "undergraduate : 0.6587\n",
            "univeristy : 0.6585\n",
            "\n",
            "Top similar words for 'doctor' (Word2Vec):\n",
            "\n",
            "physician : 0.7806\n",
            "doctors : 0.7477\n",
            "gynecologist : 0.6948\n",
            "surgeon : 0.6793\n",
            "dentist : 0.6785\n",
            "\n",
            "Top similar words for 'car' (Word2Vec):\n",
            "\n",
            "vehicle : 0.7821\n",
            "cars : 0.7424\n",
            "SUV : 0.7161\n",
            "minivan : 0.6907\n",
            "truck : 0.6736\n",
            "\n",
            "Top similar words for 'music' (Word2Vec):\n",
            "\n",
            "classical_music : 0.7198\n",
            "jazz : 0.6835\n",
            "Music : 0.6596\n",
            "Without_Donny_Kirshner : 0.6416\n",
            "songs : 0.6396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Glove and complete Neighbour words"
      ],
      "metadata": {
        "id": "nRtiaFcwSJMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained GloVe embeddings (100D)\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Choose at least 5 words\n",
        "chosen_words = [\"king\", \"university\", \"doctor\", \"car\", \"music\"]\n",
        "\n",
        "for word in chosen_words:\n",
        "    print(f\"\\nTop similar words for '{word}':\\n\")\n",
        "\n",
        "    similar_words = model.most_similar(word, topn=5)\n",
        "\n",
        "    for similar_word, score in similar_words:\n",
        "        print(f\"{similar_word} : {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do2cI5JtSOKa",
        "outputId": "1df68b43-31a9-48c2-dc0b-ca1404aea14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top similar words for 'king':\n",
            "\n",
            "prince : 0.7682\n",
            "queen : 0.7508\n",
            "son : 0.7021\n",
            "brother : 0.6986\n",
            "monarch : 0.6978\n",
            "\n",
            "Top similar words for 'university':\n",
            "\n",
            "college : 0.8294\n",
            "harvard : 0.8156\n",
            "yale : 0.8114\n",
            "professor : 0.8104\n",
            "graduate : 0.7993\n",
            "\n",
            "Top similar words for 'doctor':\n",
            "\n",
            "physician : 0.7673\n",
            "nurse : 0.7522\n",
            "dr. : 0.7175\n",
            "doctors : 0.7081\n",
            "patient : 0.7074\n",
            "\n",
            "Top similar words for 'car':\n",
            "\n",
            "vehicle : 0.8631\n",
            "truck : 0.8598\n",
            "cars : 0.8372\n",
            "driver : 0.8186\n",
            "driving : 0.7813\n",
            "\n",
            "Top similar words for 'music':\n",
            "\n",
            "musical : 0.8128\n",
            "songs : 0.7978\n",
            "dance : 0.7897\n",
            "pop : 0.7863\n",
            "recording : 0.7651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Load Word2Vec and complete word analogy"
      ],
      "metadata": {
        "id": "TOkT_ZIlSlq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained Word2Vec (better for analogies)\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Analogy 1\n",
        "result1 = model.most_similar(\n",
        "    positive=[\"king\", \"woman\"],\n",
        "    negative=[\"man\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "# Analogy 2\n",
        "result2 = model.most_similar(\n",
        "    positive=[\"paris\", \"india\"],\n",
        "    negative=[\"france\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "# Analogy 3\n",
        "result3 = model.most_similar(\n",
        "    positive=[\"teacher\", \"hospital\"],\n",
        "    negative=[\"school\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "print(\"\\nking - man + woman = ?\")\n",
        "print(result1)\n",
        "\n",
        "print(\"\\nparis - france + india = ?\")\n",
        "print(result2)\n",
        "\n",
        "print(\"\\nteacher - school + hospital = ?\")\n",
        "print(result3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCjG8oK5SonS",
        "outputId": "d3ba8596-206c-457c-e712-0e760afe47c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "king - man + woman = ?\n",
            "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581)]\n",
            "\n",
            "paris - france + india = ?\n",
            "[('chennai', 0.5442505478858948), ('delhi', 0.5149926543235779), ('mumbai', 0.5024341344833374), ('hyderabad', 0.49932485818862915), ('gujarat', 0.48732805252075195)]\n",
            "\n",
            "teacher - school + hospital = ?\n",
            "[('Hospital', 0.6331106424331665), ('nurse', 0.6280134320259094), ('hopsital', 0.6217317581176758), ('intensive_care', 0.5683753490447998), ('Hosptial', 0.5647749304771423)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe – Word Analogy"
      ],
      "metadata": {
        "id": "YZPxV7cQTvSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nGloVe Analogies:\\n\")\n",
        "\n",
        "result1 = model.most_similar(\n",
        "    positive=[\"king\", \"woman\"],\n",
        "    negative=[\"man\"],\n",
        "    topn=3\n",
        ")\n",
        "\n",
        "result2 = model.most_similar(\n",
        "    positive=[\"paris\", \"india\"],\n",
        "    negative=[\"france\"],\n",
        "    topn=3\n",
        ")\n",
        "\n",
        "print(\"king - man + woman =\", result1)\n",
        "print(\"paris - france + india =\", result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lGVfH5vTym8",
        "outputId": "55a898c8-842c-4c06-9cc1-52b0a7bd5c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GloVe Analogies:\n",
            "\n",
            "king - man + woman = [('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951)]\n",
            "paris - france + india = [('chennai', 0.5442505478858948), ('delhi', 0.5149926543235779), ('mumbai', 0.5024341344833374)]\n"
          ]
        }
      ]
    }
  ]
}